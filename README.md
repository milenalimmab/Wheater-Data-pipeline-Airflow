# ğŸŒ¤ï¸ Weather Data Pipeline with Apache Airflow

A data pipeline that automatically extracts weather data from OpenWeatherMap API, transforms it, and loads it into AWS S3 for further analysis.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Configuration](#configuration)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Data Schema](#data-schema)


## âœ¨ Features

- **Automated Geocoding**: Automatically fetches coordinates for any city using OpenWeatherMap Geocoding API
- **Data Transformation**: Converts temperatures from Kelvin to Celsius and formats timestamps
- **AWS S3 Integration**: Stores processed weather data in S3 buckets with organized structure
- **Highly Configurable**: Easy to configure via Airflow Variables and Parameters
- **Scheduled Execution**: Runs daily by default (customizable)
- **Clean Output**: Generates well-structured CSV files ready for analysis

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Get City Coordinates   â”‚  â† Geocoding API
â”‚   (HttpOperator)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Check API Availability â”‚  â† Health Check
â”‚     (HttpSensor)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Extract Weather Data   â”‚  â† Weather API
â”‚     (HttpOperator)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Transform Data        â”‚  â† Data Processing
â”‚  (PythonOperator)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Upload to S3         â”‚  â† AWS S3
â”‚  (PythonOperator)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Prerequisites

Ensure you have:

- **Python 3.8+** installed
- **Apache Airflow 2.7+** installed
- **AWS Account** with S3 access
- **OpenWeatherMap API key** ([Get one free here](https://openweathermap.org/api))
- **AWS credentials** (Access Key ID and Secret Access Key)

## âš™ï¸ Configuration

### Step 1: Configure HTTP Connection

1. Access Airflow UI
2. Go to **Admin â†’ Connections**
3. Click **+** to add a new connection
4. Fill in:
   - **Connection Id**: `weathermap_api`
   - **Connection Type**: `HTTP`
   - **Host**: `https://api.openweathermap.org`
5. Click **Save**

### Step 2: Set Airflow Variables

Go to **Admin â†’ Variables** and create the following variables:

| Key | Example Value | Description |
|-----|---------------|-------------|
| `openweather_api_key` | `your_api_key_here` | OpenWeatherMap API key |
| `aws_access_key_id` | `AKIAIOSFODNN7EXAMPLE` | AWS Access Key ID |
| `aws_secret_access_key` | `wJalrXUtnFEMI...` | AWS Secret Access Key |
| `s3_bucket_name` | `my-weather-data-bucket` | S3 bucket name |
| `aws_region` | `us-east-1` | AWS region (e.g., sa-east-1) |
| `default city` | `SÃ£o Paulo` | Default city |

This increases security by not exposing your keys directly in the code and also makes it easier to change cities and regions.

### Run the DAG

**Via UI**
1. Go to `http://localhost:8080`
2. Find `weather_data_pipeline` DAG
3. Toggle it **ON**
4. Click **Trigger DAG** (play button)



## ğŸ“Š Data Schema

The pipeline generates CSV files with the following structure:

| Column | Type | Description |
|--------|------|-------------|
| City | string | City name |
| Description | string | Weather description (e.g., "clear sky") |
| Temperature (C) | float | Current temperature in Celsius |
| Feels Like (C) | float | Feels like temperature in Celsius |
| Minimum Temp (C) | float | Minimum temperature |
| Maximum Temp (C) | float | Maximum temperature |
| Pressure | int | Atmospheric pressure (hPa) |
| Humidity | int | Humidity percentage |
| Wind Speed | float | Wind speed (m/s) |
| Time of Record | datetime | Timestamp of the record |
| Sunrise (Local Time) | datetime | Sunrise time |
| Sunset (Local Time) | datetime | Sunset time |

You can also filter the data to include/exclude fields. 

**S3 Path Structure:**
```
s3://your-bucket-name/
â””â”€â”€ weather-data/
    â”œâ”€â”€ weather_data_London_20251015_143000.csv
    â”œâ”€â”€ weather_data_Paris_20251015_143500.csv
    â””â”€â”€ weather_data_Tokyo_20251015_144000.csv
```

 The filename follows the structure: weather_data_**Default_city** _ **Y%M%D** _ **h%m%s%**.csv


## ğŸ™ Acknowledgments

- [OpenWeatherMap API](https://openweathermap.org/api) - Weather data provider
- [Apache Airflow](https://airflow.apache.org/) - Workflow orchestration
- [AWS S3](https://aws.amazon.com/s3/) - Cloud storage
- [Pandas](https://pandas.pydata.org/) - Data manipulation

## ğŸ‘¤ Author

**Milena L.**

- GitHub: [@milenalimmab](https://github.com/milenalimmab)
- LinkedIn: [Milena Lima](https://www.linkedin.com/in/milenalimma/)

